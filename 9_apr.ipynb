{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7551b726-7f93-41a6-8c39-6f4d45012c7a",
   "metadata": {},
   "source": [
    "Q1. What is Bayes' theorem?\n",
    "\n",
    "Answer--> \n",
    "Bayes' theorem is a fundamental concept in probability theory and statistics that describes the relationship between conditional probabilities. It provides a way to update our beliefs or probabilities about an event based on new evidence or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc2c17-3785-4cef-8ddc-e178cb314d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cd7bb6b-155a-4ce8-847f-7fde044a0d64",
   "metadata": {},
   "source": [
    "Q2. What is the formula for Bayes' theorem?\n",
    "\n",
    "Answer--> Mathematical formula for Bayes' theorem can be stated as:\n",
    "\n",
    "    P(A∣B) = P(B∣A)⋅P(A) /  P(B)\n",
    "Where:\n",
    "\n",
    "- P(A∣B) is the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "- P(B∣A) is the probability of event B occurring given that event A has occurred.\n",
    "\n",
    "- P(A) is the prior probability of event A occurring.\n",
    "\n",
    "- P(B) is the prior probability of event B occurring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbdd908-e9f3-4d69-b935-034ed1377123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f9a1df6-8d3e-4d33-b649-b3fc3c20da48",
   "metadata": {},
   "source": [
    "Q3. How is Bayes' theorem used in practice?\n",
    "\n",
    "Answer--> Bayes' theorem is used in various practical applications to update probabilities based on new evidence or information. Here are some basic examples of how Bayes' theorem is applied:\n",
    "\n",
    "- Weather Forecasting:\n",
    "In weather forecasting, historical weather data and current conditions are used to predict future weather. Bayes' theorem can help update weather predictions based on new observations and data.\n",
    "\n",
    "- Spam Filtering:\n",
    "In email spam filtering, Bayes' theorem is used to determine the probability that an incoming email is spam or not spam based on the occurrence of certain words or patterns in the email content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1ab961-b441-4b16-8da6-590f3483377c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "abfe5619-2dae-462a-9fa9-43754ecb2041",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between Bayes' theorem and conditional probability?\n",
    "\n",
    "Answer--> Bayes' theorem and conditional probability are interconnected concepts. Bayes' theorem builds upon conditional probability and enables us to update our beliefs about events by incorporating new evidence or information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8356b4-39fe-43e1-9ac9-c701bd48b630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ca73632-4069-4149-8c7b-fe0c8c2e3cdc",
   "metadata": {},
   "source": [
    "Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\n",
    "\n",
    "Answer--> \n",
    "Choosing the appropriate type of Naive Bayes classifier depends on the characteristics of your data and the assumptions that best match the underlying distribution of your features. There are three main types of Naive Bayes classifiers. Here's how you can choose the right one for your problem:\n",
    "\n",
    "#### Gaussian Naive Bayes:\n",
    "\n",
    "- Use when your features follow a continuous Gaussian (normal) distribution.\n",
    "- Suitable for numerical features.\n",
    "- Assumes that each class follows a Gaussian distribution.\n",
    "\n",
    "#### Multinomial Naive Bayes:\n",
    "\n",
    "- Use when your features represent discrete counts, such as word frequencies in text data.\n",
    "- Suitable for text classification or any dataset with categorical features.\n",
    "\n",
    "#### Bernoulli Naive Bayes:\n",
    "\n",
    "- Use when your features are binary (e.g., presence or absence of a feature).\n",
    "- Suitable for text classification, spam filtering, and other binary feature datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66850b8-061a-4c11-ab35-1c8fd3d76001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73372025-8778-4c45-8019-fc7896a71993",
   "metadata": {},
   "source": [
    "Q6. You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "\n",
    "    Class X1=1  X1=2  X1=3  X2=1  X2=2  X2=3  X2=4\n",
    "    \n",
    "     A      3      3     4    4     3     3      3 \n",
    "     B      2      2     1    2     2     2      3 \n",
    "    \n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\n",
    "\n",
    "Answer--> To classify the new instance with features \\(X1 = 3\\) and \\(X2 = 4\\) using Naive Bayes, we need to calculate the class probabilities for both classes (A and B) and choose the class with the higher probability. Given the provided frequency table and assuming equal prior probabilities for each class, let's calculate the probabilities for both classes:\n",
    "\n",
    "**Class A:**\n",
    "- P(X1 = 3 | A) = 4/6\n",
    "- (P(X2 = 4 | A) = 3/6\n",
    "\n",
    "**Class B:**\n",
    "- P(X1 = 3 | B) = 1/9\n",
    "- P(X2 = 4 | B) = 3/9\n",
    "\n",
    "Using the Naive Bayes formula, we calculate the posterior probability for each class:\n",
    "\n",
    "For Class A:\n",
    "[ P(A | X1=3, X2=4) = P(X1=3 | A) * P(X2=4 | A) ]\n",
    "\n",
    "For Class B:\n",
    "[ P(B | X1=3, X2=4) = P(X1=3 | B) * P(X2=4 | B) \\]\n",
    "\n",
    "Since we are assuming equal prior probabilities for both classes, we don't need to include the prior probabilities in the calculations.\n",
    "\n",
    "Calculating the values:\n",
    "- ( P(A | X1=3, X2=4) = 4/6 * 3/16 = {12/256} )\n",
    "- ( P(B | X1=3, X2=4) = 1/9* 3/9 = 3/81)\n",
    "\n",
    "Comparing the probabilities, we find that ( P(A | X1=3, X2=4) > P(B | X1=3, X2=4) ), which means that the Naive Bayes classifier would predict the new instance to belong to Class A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e3590c-ef7b-4a34-a454-f7cc6df02e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bab3389-e2d5-4c88-b61b-210271e3bfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
